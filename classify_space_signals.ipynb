{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KeHZOb76Eoao"
   },
   "source": [
    "<h2 align=center> Classify Radio Signals from Outer Space with Keras</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Allen_Telescope.jpg)\n",
    "[Allen Telescope Array](https://flickr.com/photos/93452909@N00/5656086917) by [brewbooks](https://www.flickr.com/people/93452909@N00) is licensed under [CC BY 2.0](https://creativecommons.org/licenses/by/2.0/)\\\n",
    "[Coursera Link](https://www.coursera.org/projects/classify-radio-signals-space-keras-cnn)\\\n",
    "Create virtual environment\\\n",
    "Unzip dataset.zip\\\n",
    "In terminal, run:\\\n",
    "    - .venv\\Scripts\\Activate.ps1\\\n",
    "    - pip install --upgrade pip ipykernel scikit-learn tensorflow pandas numpy matplotlib seaborn livelossplot\\\n",
    "    - pip freeze > requirements.txt\\\n",
    "\n",
    "### Training a Convolutional Neural Network (CNN) model to classify space signals into four categories: \"squiggle\", \"narrowband\", \"noise\", and \"narrowbanddrd\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fB2voc0SFB0W"
   },
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2pO03vSBEc6D"
   },
   "outputs": [],
   "source": [
    "import warnings;warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "\n",
    "%matplotlib inline\n",
    "print('Tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYt4AvyeFJPn"
   },
   "source": [
    "## Step 2: Load and Preprocess SETI Data (signals have been transformed to images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oDubuBkZEgaE"
   },
   "outputs": [],
   "source": [
    "train_images = pd.read_csv('dataset/train/images.csv', header=None)\n",
    "train_labels = pd.read_csv('dataset/train/labels.csv', header=None)\n",
    "\n",
    "x_train = train_images.values.reshape(3200, 64, 128, 1)\n",
    "y_train = train_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCQy-0ZsEgfa"
   },
   "outputs": [],
   "source": [
    "val_images = pd.read_csv('dataset/validation/images.csv', header=None)\n",
    "val_labels = pd.read_csv('dataset/validation/labels.csv', header=None)\n",
    "\n",
    "x_val = val_images.values.reshape(800, 64, 128, 1)\n",
    "y_val = val_labels.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pAC1DPXrF8oS"
   },
   "source": [
    "## Step 3: Plot 2D Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTOmtFOaEgpN"
   },
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(12,12))\n",
    "for i in range(1,4):\n",
    "    plt.subplot(1,3,i)\n",
    "    img = np.squeeze(x_train[np.random.randint(0, x_train.shape[0])])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(x_train[3]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jqJJhvGkGqz1"
   },
   "source": [
    "## Step 4: Create Training and Validation Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48xSPckOGwoV"
   },
   "outputs": [],
   "source": [
    "dataGen_train = ImageDataGenerator(horizontal_flip=True, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2)\n",
    "dataGen_train.fit(x_train)\n",
    "\n",
    "dataGen_val = ImageDataGenerator(horizontal_flip=True)\n",
    "dataGen_val.fit(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-UEvdu2bHKEQ"
   },
   "source": [
    "## Step 5: CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqpC-6NQGwrQ"
   },
   "outputs": [],
   "source": [
    "img_shape = (64, 128, 1)\n",
    "num_classes = 4\n",
    "\n",
    "model = Sequential([\n",
    "    ##-> 1st Convolution Layer\n",
    "    Conv2D(32, (5, 5), padding='same', input_shape=img_shape),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    ##-> 2nd Convolution layer\n",
    "    Conv2D(64, (5, 5), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    ##-> Flattening\n",
    "    Flatten(),\n",
    "    \n",
    "    ##-> Fully Connected layer\n",
    "    Dense(1024),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LmXdhu-6H7Q5"
   },
   "source": [
    "## Step 6: Schedule Learning Rate and Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNEKTceqGwuX"
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.005\n",
    "\n",
    "lr_sched = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=initial_learning_rate, decay_steps=100, decay_rate=0.96, staircase=True)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=lr_sched), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tfqcUL6DIKDR"
   },
   "source": [
    "## Step 7: CallBacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fuvoWEXIQfZ"
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss', save_weights_only=True, mode='min', verbose=1)\n",
    "#? Add more callbacks like EarlyStopping?\n",
    "callbacks = [PlotLossesCallback(), checkpoint]#, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    dataGen_train.flow(x_train, y_train, batch_size=batch_size),\n",
    "    steps_per_epoch=len(x_train) // batch_size,\n",
    "    validation_data=dataGen_val.flow(x_val, y_val, batch_size=batch_size),\n",
    "    validation_steps=len(x_val) // batch_size,\n",
    "    epochs=12,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Out7Wpj_Ic-g"
   },
   "source": [
    "## Step 9: Model Evaluation, Prediction, Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJTxGMVEIdlp"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_val, y_val)\n",
    "\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "y_pred = np.argmax(model.predict(x_val), axis=1)\n",
    "print(metrics.classification_report(y_true, y_pred, zero_division=0))\n",
    "print(\"Classification accuracy: %0.6f\" % metrics.accuracy_score(y_true, y_pred))\n",
    "\n",
    "##-> Visualize\n",
    "labels = [\"squiggle\", \"narrowband\", \"noise\", \"narrowbanddrd\"]\n",
    "confusion_mtx = metrics.confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt='g', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.xticks(ticks=np.arange(num_classes), labels=labels)\n",
    "plt.yticks(ticks=np.arange(num_classes), labels=labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Completed_Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
